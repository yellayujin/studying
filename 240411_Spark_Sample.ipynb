{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yellayujin/studying/blob/main/240411_Spark_Sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark 설치\n",
        "- 주소 : https://spark.apache.org/downloads.html\n",
        "- 주소 : https://www.apache.org/dyn/closer.lua/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "2My4mB8HOwKp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAOLCPndOrFf",
        "outputId": "8e074804-3792-4d4d-db71-a7a0ee56f5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "openjdk-8-jdk-headless is already the newest version (8u402-ga-2ubuntu1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar -zxf spark-3.5.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "zF8Gtg6cQZcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyzZf8nxWWw8",
        "outputId": "d7a30fef-e8ae-4165-fe60-385254637337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  spark-3.5.1-bin-hadoop3  spark-3.5.1-bin-hadoop3.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경변수 설정\n",
        "- 버전에 따라 변경한다."
      ],
      "metadata": {
        "id": "Vu3Ejd4xPd1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\""
      ],
      "metadata": {
        "id": "fOSCltuRPdah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PySpark 설치"
      ],
      "metadata": {
        "id": "FE7p9ClXWrvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark -q"
      ],
      "metadata": {
        "id": "0qjGQ1-pWrZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "6CHGdFTUWuwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "spark_version = pyspark.__version__\n",
        "print(\"Apache Spark 버전 확인: \" + spark_version)"
      ],
      "metadata": {
        "id": "trrbihXWWzis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adaaf4e4-cda5-495b-b58e-d30b288aaaa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apache Spark 버전 확인: 3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트"
      ],
      "metadata": {
        "id": "ExLKN0PYW4fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('mulCamp34').config('spark.ui.port', '4050').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "id": "xnMpznRMW5OU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "09236930-8e99-4a0d-9fdb-dfa352447073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7994243163b0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://971857301b30:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>mulCamp34</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WoN177o7bxgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"\n",
        "Once upon a time, in a land far, far away, there lived a dragon who loved to collect treasures.\n",
        "Every day, the dragon would fly across the kingdoms, searching for precious items to add to his collection.\n",
        "\"\"\"\n",
        "\n",
        "lines = spark.sparkContext.parallelize(sample_text.split(\"\\n\"))\n",
        "wordCounts = lines.flatMap(lambda line: line.split(\" \")) \\\n",
        "             .map(lambda word: (word, 1)) \\\n",
        "             .reduceByKey(lambda a, b: a + b)\n",
        "for word, count in wordCounts.collect():\n",
        "    print(f\"{word}: {count}\")"
      ],
      "metadata": {
        "id": "0opTg6RLX2p6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2a147e-6199-407b-8754-6f4758d3666c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ": 2\n",
            "Once: 1\n",
            "upon: 1\n",
            "in: 1\n",
            "far,: 1\n",
            "far: 1\n",
            "there: 1\n",
            "lived: 1\n",
            "dragon: 2\n",
            "loved: 1\n",
            "Every: 1\n",
            "would: 1\n",
            "fly: 1\n",
            "kingdoms,: 1\n",
            "precious: 1\n",
            "items: 1\n",
            "his: 1\n",
            "collection.: 1\n",
            "a: 3\n",
            "time,: 1\n",
            "land: 1\n",
            "away,: 1\n",
            "who: 1\n",
            "to: 3\n",
            "collect: 1\n",
            "treasures.: 1\n",
            "day,: 1\n",
            "the: 2\n",
            "across: 1\n",
            "searching: 1\n",
            "for: 1\n",
            "add: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark 종료"
      ],
      "metadata": {
        "id": "9kG1SWbjYSxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "kzMLBq3GYShp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}